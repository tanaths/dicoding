# -*- coding: utf-8 -*-
"""Submission 1. Dicoding

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1svihuq6oGeAcH9IU7zbRgCLWubKfkNDE

# **Project Domain**

> **Background**:
The wine is one of popular drink in the world. The wind industry may depict of slow life and bucolic landscape but it is a significant business sector. The most establihed wine market are in Europe, such as Portugal, Italy, and France as they have highest per capita consumption at over 35 liters/person/year. Nowadays, we could see them on various occasions, one of them is white wine.

> The earliest use of white wine was founded in ancient Greek era. In addition, the production process of white wine contains several complex process. To find good white wine, The Wine & Spirit Education Trust (WSET) evaluate with various aspects, such as appearance of wine, smell of wine, the oxygen containts in it, and the last is taste of wine.

# **Business Understanding**

> **Problem statements**:
* To know the quality of wine, apply the complex tasting process above will be very waste of time and resources.
* the current datasets is imbalanced  and has many features so choosing suitable algorithm is needed

> **Goals**: In order to improve the quality of white wine production, this study aims to:
*   Explore which features of ingredients and chemical characteristics that has highest impact against the quality of white wine.
*   Develop and determine the best model to predict the quality of wine based on various features and amount of datasets

> **Solution statements**:
* Testing the datasets with 3 algorithm such a logistic regression, SVM, and random forest classifier to determine which algorithm that has best result.
* The metric we've applied was ROC and AUC since it was more suitable because white wine quality has imbalance number of datasets.

# **Data Understanding**

> The dataset we used are Wine Quality Dataset from [UCI Datasets](https://archive.ics.uci.edu/dataset/186/wine+quality). The white wine quality datasets has multivariate characteristics and it contains 4898 instances and 11 features with real type.

> The white wine datasets has 12 attributes with following:
* fixed_acidity: as the ones that remains in a liquid when it's boiled, do not evaporate readily
* volatile_acidity: the measure of wine's gaseous acid that leads to smell and taste of vinegar.
* citric_acid: acid complement of spesific flavor to increase freshness and acidity of wine during fermentation process
* residual_sugar: the amount of sugar remaining after fermentation ended
* chlorides: the amount of salt in wine (add saltiness)
* free_sulfur_dioxide:act as for prevent oxidation of wine and microbial growth
* total_sulfur_dioxide:
* density: the amount of SO2 that is free in the wine plus the portion that is bound
* pH: level of acidity
* sulphates: act as help to protect the wine against potential oxidation or bacterial exposure in the wine
* alcohol: the amount of alcohol consentrate in wine
* quality: the quality of the wine

**Understanding data steps**:
To further understanding the data, we've applied _EDA (Exploratory Data Analysis)_ which contains several steps:
* Checking the big picture of datasets (describe of datasets, info of datasets and the shape)
* Checking the null value
* Checking the distribution
* Depict heatmap for correlation

## **Exploratory Data Analysis**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

from google.colab import drive
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import roc_curve, auc, roc_auc_score
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score,precision_score, recall_score

drive.mount('/content/drive', force_remount=True)

#load the dataset
wine = pd.read_csv('/content/drive/MyDrive/Internship/DICODING/winequality-white.csv', sep=';')
wine

"""describe the dataset"""

wine.describe(include='all')

"""Grouping wine quality to know average value for each features for every category"""

wine.groupby('quality').mean()

"""Count the total number of each quality"""

wine['quality'].value_counts()

"""The shape of datasets"""

wine.shape

"""The info of data type"""

wine.info()

"""**Checking null value**"""

wine.isna().sum()

"""## **Checking Distribution**"""

plt.figure(figsize=(32,22))

for i in range(1, min(wine.shape[1]+1, 13)):
  plt.subplot(4,3,i)
  plt.hist(wine.iloc[:,i-1], bins=50)
  plt.title(wine.columns[i-1], fontsize=18)

"""Picture 1. Feature Distribution. Based on the graph, the feature almost followed normal distribution although a few of them is right skewness

## **Heatmap for Correlation**
"""

plt.figure(figsize=(10,8))
corr_matrix = wine.corr().round(2)

sns.heatmap(data=corr_matrix,
            annot=True,
            cmap='coolwarm',
            linewidth=0.5)
plt.title('Correlation matrix', size=20)

"""Picture 2. Corelation Map
> `alcohol` and `density` feature has the biggest corelation with target feature `quality` (**about 0.44**). Besides, `sulphates`, `free sulfur dioxide`, and `citric acid` has the smallest corelation (**about -0.01 ~ 0.05**). Thus, the features will be  **dropped**. The rest has weak positive correlation against `quality` such as`pH`. And weak negative correlation such as `fixed acidity`, `volatile acidity`, `residual sugar`, `chlorides`, and `total sulfure dioxide`. Thus, both weak correlation will still included as feature importances.

**Correlation betweeen each of features, represents in pairplot**
"""

sns.pairplot(wine)

"""Picture 3. Pairplot between features
> Based on feature importances, fixed acidity, volatile acidity, and citric acid becomes important feature for quality of white wine. Quality of the wine decrease with increase of volatile acidity. Meanwhile, quality of the wine increase with increase of citric acid and fixed acidity amount

# **Data Preparation**

Data preparation is done by several steps included:
* Feature Importances by utilize Random Forest Classifier
* Encoding category from making binary classification based on target variable (which is 'quality')
* Feature engineering by StandardScaler()
"""

wine['is_good_quality'] = [1 if x>=7 else 0 for x in wine['quality']] #below 7 is low quality and >=7 is good quality
wine['is_good_quality'].value_counts()

"""## **Feature Importances**

Make new variable that contain input variable (x) and output variable (y)
"""

x = wine.drop(['quality','is_good_quality','sulphates','citric acid', 'free sulfur dioxide'], axis=1)
y = wine['is_good_quality']

x.head()

y.head()

"""## **Feature Engineering**

spltting dataset into 80% training and 20% testing
"""

#split dataset
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

"""Normalize value from accross input variable using standardscaler"""

scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

"""# **Modelling**

**Logistic Regression**
"""

model_lr = LogisticRegression(C=0.1, penalty='l2', solver='liblinear')
model_lr.fit(x_train, y_train)

#predict
prob_lr = model_lr.predict_proba(x_test)[:,1]

"""**Support Vector Machine**"""

model_svm = SVC(C=0.1,
                gamma='scale',
                kernel='rbf',
                probability=True)
model_svm.fit(x_train, y_train)

#predict
prob_svm = model_svm.predict_proba(x_test)[:,1]

"""> one of main reason using rbf kernel because it is more complex and efficient at the same time that it can combine multiple polynomial kernels (nonlinear) to project the non-linearly separable data into higher dimensional space so that it can be separable using a hyperplane.

> we also experiments using linear kernel and it generated a bit lower accuracy and ROC value than rbf kernel (linear with ROC 0,79 and rbf with ROC 0,80)

**Random Forest Classifier**
"""

model_random_forest = RandomForestClassifier()
model_random_forest.fit(x_train, y_train)

#predict
prob_rf = model_random_forest.predict_proba(x_test)[:,1]

"""> For RFC we only using default parameters. Default Random forest already well-suited for the datasets in the specific case.

# **Evaluation**

The evaluation of model is done by using ROC curve and AUC score.
"""

#calculate roc and auc
#fpr stands for false positive rate (recall/sensitivity)
#tpr stands for true positive rate (inverse recall)

y_test = pd.Series(y_test).replace({'Good':1, 'Bad':0})

#logistic regression
lr_roc = roc_auc_score(y_test, prob_lr)
lr_fpr, lr_tpr, lr_threshold = roc_curve(y_test, prob_lr)
lr_auc = auc(lr_fpr, lr_tpr)

#SVM
svm_roc = roc_auc_score(y_test, prob_svm)
svm_fpr, svm_tpr, svm_threshold = roc_curve(y_test, prob_svm)
svm_auc = auc(svm_fpr, svm_tpr)

#RFC
rfc_roc = roc_auc_score(y_test, prob_rf)
rfc_fpr, rfc_tpr, rfc_threshold = roc_curve(y_test, prob_rf)
rfc_auc = auc(rfc_fpr, rfc_tpr)

"""visualize roc and auc score for each of algorithm"""

#visualize roc and auc
plt.figure(figsize=(12,7))
plt.plot(lr_fpr, lr_tpr, label = f'AUC (Logistic Regression) = {lr_roc:.2f}', linewidth=4)
plt.plot(svm_fpr, svm_tpr, label = f'AUC (SVM Linear) = {svm_roc:.2f}', linewidth=4)
plt.plot(rfc_fpr, rfc_tpr, label = f'AUC (Random Forest Classifier) = {rfc_roc:.2f}', linewidth=4)
plt.title('ROC CURVE', size=15)
plt.xlabel('False Positive Rate (Inverse Sensitifivity)', size=12)
plt.ylabel('True Positive Rate(Sensitivity)', size=12)
plt.legend()

"""> After comparing these models using ROC curve and AUC score, it can be concluded that `random forest classifier has the best results`, followiwng `SVM` and `logistic regression`

 **Explanations**: The success of Random Forest Classifier in this case could be attributed to its ensemble nature, which inherently handles complex relationships and is less sensitive to hyperparameter tuning. The default settings might have been appropriate for the dataset, while the logistic regression and SVM models might not have been optimized effectively with the chosen hyperparameters. However, the end result of SVM is slightly better than logistic regression because of the kernel trick.
"""

